name: 'Generate Combined Deployment Matrices'
description: 'Parses multiple deployment config files and generates combined matrices with secret processing'
inputs:
  resource_paths:
    description: 'Comma-separated paths to resources (e.g., cloud-formation/rcc/a-crs-spa,cloud-formation/rcc/another-resource)'
    required: true
  specific_environment:
    description: 'Specific environment to deploy (empty for all configured)'
    required: false
    default: ''
  process_secrets:
    description: 'Process secrets in parameters (true/false)'
    required: false
    default: 'true'

outputs:
  dev_matrix:
    description: 'Matrix for DEV deployments'
    value: ${{ steps.generate-matrices.outputs.dev_matrix }}
  int_matrix:
    description: 'Matrix for INT deployments'
    value: ${{ steps.generate-matrices.outputs.int_matrix }}
  prod_matrix:
    description: 'Matrix for PROD deployments'
    value: ${{ steps.generate-matrices.outputs.prod_matrix }}

runs:
  using: "composite"
  steps:
    - name: Install yq
      shell: bash
      run: |
        if ! command -v yq &> /dev/null; then
          echo "Installing yq..."
          VERSION=v4.30.8
          BINARY=yq_linux_amd64
          wget https://github.com/mikefarah/yq/releases/download/${VERSION}/${BINARY}.tar.gz -O - | \
            tar xz
          chmod +x ${BINARY}
          sudo mv ${BINARY} /usr/bin/yq || mkdir -p $HOME/bin && mv ${BINARY} $HOME/bin/yq && echo "$HOME/bin" >> $GITHUB_PATH
        fi

    - name: Generate matrices with Python
      id: generate-matrices
      shell: python
      run: |
        import os
        import re
        import json
        import shutil
        import tempfile
        import subprocess
        from pathlib import Path

        # Get inputs
        resource_paths = "${{ inputs.resource_paths }}".split(",")
        specific_environment = "${{ inputs.specific_environment }}"
        process_secrets = "${{ inputs.process_secrets }}" == "true"

        print(f"Processing resource paths: {resource_paths}")
        print(f"Specific environment: {specific_environment or 'None'}")
        print(f"Processing secrets: {process_secrets}")

        # Initialize matrices
        dev_matrix_items = []
        int_matrix_items = []
        prod_matrix_items = []

        # Create temp directory for processed parameter files
        temp_dir = Path(tempfile.mkdtemp(prefix="matrix-params-"))
        print(f"Created temporary directory: {temp_dir}")

        def extract_secret_names(content):
            """Extract secret names from content using regex"""
            if not isinstance(content, str):
                return []
                
            pattern = r'\${{.*?secrets\.([A-Za-z0-9_-]+).*?}}'
            matches = re.findall(pattern, content)
            return matches

        def replace_secrets(content):
            """Replace secret references with their values"""
            if not isinstance(content, str) or 'secrets.' not in content:
                return content
                
            pattern = r'\${{.*?secrets\.([A-Za-z0-9_-]+).*?}}'
            
            # Find all secret references
            secret_refs = {}
            for match in re.finditer(pattern, content):
                full_match = match.group(0)  # The entire match ${{ secrets.X }}
                secret_name = match.group(1)  # Just the secret name X
                
                # Only process each unique reference once
                if full_match not in secret_refs:
                    secret_refs[full_match] = secret_name
            
            # Replace each reference with its value
            modified_content = content
            for ref, name in secret_refs.items():
                if name in os.environ:
                    print(f"Replacing secret: {name}")
                    modified_content = modified_content.replace(ref, os.environ[name])
                else:
                    print(f"Warning: Secret {name} not found in environment")
            
            return modified_content

        def process_parameter_file(file_path):
            """Process a parameter file and return the path to the processed file"""
            if not file_path or not os.path.isfile(file_path):
                return file_path
                
            print(f"Processing parameter file: {file_path}")
            
            # Read the file content
            with open(file_path, 'r') as f:
                content = f.read()
            
            # Check if the file contains secrets
            if 'secrets.' not in content:
                print("No secrets found in parameter file")
                return file_path
                
            # Replace secrets in the content
            processed_content = replace_secrets(content)
            
            # Only create a new file if content changed
            if processed_content != content:
                proc_file = temp_dir / f"processed_{os.path.basename(file_path)}"
                with open(proc_file, 'w') as f:
                    f.write(processed_content)
                print(f"Created processed parameter file: {proc_file}")
                return str(proc_file)
            
            return file_path

        def process_inline_parameters(params):
            """Process inline parameters in either array or object format"""
            if not params:
                return params
                
            # Check if we have inline parameters
            if 'inline-parameters' not in params:
                return params
                
            inline_params = params['inline-parameters']
            
            # Skip if not a format we recognize or no secrets present
            if not inline_params or (isinstance(inline_params, str) and 'secrets.' not in inline_params):
                return params
                
            print("Processing inline parameters")
            
            # Handle array format (list of dicts with ParameterKey/ParameterValue)
            if isinstance(inline_params, list):
                for item in inline_params:
                    if isinstance(item, dict) and 'ParameterValue' in item:
                        value = item['ParameterValue']
                        if isinstance(value, str) and 'secrets.' in value:
                            item['ParameterValue'] = replace_secrets(value)
            
            # Handle object format (simple key/value pairs)
            elif isinstance(inline_params, dict):
                for key, value in inline_params.items():
                    if isinstance(value, str) and 'secrets.' in value:
                        inline_params[key] = replace_secrets(value)
            
            # Update the parameters with processed inline params
            params['inline-parameters'] = inline_params
            return params

        def process_parameters(params):
            """Process both parameter file and inline parameters"""
            if not process_secrets or not params:
                return params
                
            # Convert to dict if it's a string (JSON)
            if isinstance(params, str):
                try:
                    params = json.loads(params)
                except json.JSONDecodeError:
                    print(f"Error parsing parameters JSON: {params}")
                    return params
            
            # Process parameter file if present
            if 'parameter-file' in params and params['parameter-file']:
                processed_file = process_parameter_file(params['parameter-file'])
                params['parameter-file'] = processed_file
            
            # Process inline parameters
            params = process_inline_parameters(params)
            
            return params

        # Process each resource path
        for resource_path in resource_paths:
            resource_path = resource_path.strip()
            if not resource_path:
                continue
                
            print(f"Processing resource path: {resource_path}")
            
            # Try both YAML and YML extensions
            config_path = os.path.join(resource_path, "deployment-config.yaml")
            if not os.path.isfile(config_path):
                config_path = os.path.join(resource_path, "deployment-config.yml")
                if not os.path.isfile(config_path):
                    print(f"Warning: Configuration file not found for {resource_path}")
                    continue
            
            # Read YAML config file and convert to JSON
            print(f"Reading YAML configuration from {config_path}")
            try:
                result = subprocess.run(['yq', '-o=json', 'eval', '.', config_path], 
                                      capture_output=True, text=True, check=True)
                config_content = result.stdout
                config_json = json.loads(config_content)
            except (subprocess.CalledProcessError, json.JSONDecodeError) as e:
                print(f"Error processing config file {config_path}: {e}")
                continue
            
            # Extract app and resource from path
            app = os.path.dirname(resource_path)
            resource = os.path.basename(resource_path)
            
            print(f"Using APP={app} and RESOURCE={resource}")
            
            # Get environments list
            environments = []
            try:
                environments = config_json['deployments'][0]['environments']
            except (KeyError, IndexError):
                print(f"Warning: No environments found in {config_path}")
                continue
            
            print(f"Found environments: {environments}")
            
            # Filter by specific environment if provided
            if specific_environment:
                if specific_environment in environments:
                    environments = [specific_environment]
                else:
                    print(f"Warning: Specified environment {specific_environment} not found in {config_path}")
                    continue
            
            # Process each environment for this resource
            for env in environments:
                print(f"Processing environment: {env} for {resource_path}")
                
                try:
                    # Extract parameters
                    params = config_json['deployments'][0]['parameters'].get(env, {})
                    runner = config_json['deployments'][0]['runners'].get(env)
                    gh_env = config_json['deployments'][0]['github_environments'].get(env)
                    aws_region = config_json['deployments'][0]['aws_regions'].get(env)
                    aws_role_secret = config_json['deployments'][0]['aws_role_secrets'].get(env, "AWS_ROLE_TO_ASSUME")
                    cfn_role_secret = config_json['deployments'][0]['cfn_role_secrets'].get(env, "CFN_ROLE_ARN")
                    iam_role_secret = config_json['deployments'][0]['iam_execution_role_secrets'].get(env, "IAM_EXECUTION_ROLE_ARN")
                    vars_config = config_json['deployments'][0]['github_vars'].get(env, {})
                    
                    # Skip if any required field is empty
                    if not params or not runner or not gh_env or not aws_region:
                        print(f"Warning: Missing required configuration for {resource_path} in {env} environment")
                        continue
                    
                    # Process secrets in parameters
                    processed_params = process_parameters(params)
                    
                    # Create matrix item
                    matrix_item = {
                        "application": app,
                        "resource": resource,
                        "environment": env,
                        "runner": runner,
                        "github_environment": gh_env,
                        "aws_region": aws_region,
                        "aws_role_secret": aws_role_secret,
                        "cfn_role_secret": cfn_role_secret,
                        "iam_role_secret": iam_role_secret,
                        "github_vars": vars_config,
                        "parameters": processed_params
                    }
                    
                    # Add to appropriate matrix based on environment
                    if env == "dev":
                        dev_matrix_items.append(matrix_item)
                    elif env == "int":
                        int_matrix_items.append(matrix_item)
                    elif env == "prod":
                        prod_matrix_items.append(matrix_item)
                
                except Exception as e:
                    print(f"Error processing environment {env}: {e}")
                    continue
        
        # Construct environment-specific matrices
        dev_matrix = {"include": dev_matrix_items}
        int_matrix = {"include": int_matrix_items}
        prod_matrix = {"include": prod_matrix_items}
        
        # Verify JSON is valid
        try:
            dev_matrix_json = json.dumps(dev_matrix)
            int_matrix_json = json.dumps(int_matrix)
            prod_matrix_json = json.dumps(prod_matrix)
        except Exception as e:
            print(f"Error serializing matrices to JSON: {e}")
            exit(1)
        
        # Write matrices to outputs
        with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
            f.write("dev_matrix<<EOF\n")
            f.write(dev_matrix_json + "\n")
            f.write("EOF\n")
            
            f.write("int_matrix<<EOF\n")
            f.write(int_matrix_json + "\n")
            f.write("EOF\n")
            
            f.write("prod_matrix<<EOF\n")
            f.write(prod_matrix_json + "\n")
            f.write("EOF\n")
            
        print(f"Generated matrices: DEV({len(dev_matrix_items)}), INT({len(int_matrix_items)}), PROD({len(prod_matrix_items)})")